{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kmeans.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMiZsupk3bMSMFmqR3jSj9+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ilovely11/ly11/blob/master/Kmeans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8pBcVelx2-Q",
        "colab_type": "text"
      },
      "source": [
        "#K Means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EComseqKx5vN",
        "colab_type": "text"
      },
      "source": [
        "Today we'll be going over K Means. This is the first *unsupervised* algorithm we'll go through. That is, there will be no assumption of labels in our data. \n",
        "\n",
        "Credits: We used a guide written by Tony Yiu on https://towardsdatascience.com/k-means-clustering-from-scratch-6a9d19cafc25 to get an idea of the concept behind the algorithm. However, our implementation is a little different.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me0Lohfmy0ke",
        "colab_type": "text"
      },
      "source": [
        "#Theory of K Means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTf0fng1y4E7",
        "colab_type": "text"
      },
      "source": [
        "Well, this sounds a lot like KNN, but it's not. Like KNN, there isn't a loss function; unlike KNN, however, K Means is unsupervised. \n",
        "\n",
        "\n",
        "We'll go though the general steps of how to implement K means:\n",
        "1.   Randomly pick K set of coordinates for the center of clusters.\n",
        "2.   Calculate the distance between each point to each cluster.\n",
        "3.   Place each point in the cluster it's closest too.\n",
        "4.   Calculate the new center of each cluster.\n",
        "5.   Rinse and repeat till the center doesn't change.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPs6oN1a1eIT",
        "colab_type": "text"
      },
      "source": [
        "#Load Libraries and Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Kpqbz8xYDy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6AE5PisQ2r7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris = datasets.load_iris()\n",
        "Z = iris.data[:, :2]  # we only take the first two features.\n",
        "y = iris.target\n",
        "z = y.reshape((y.shape[0],1))\n",
        "for n in range(len(z)):\n",
        "    if (z[n] != 0):\n",
        "        z[n] = 1\n",
        "X = np.hstack((Z, z))\n",
        "\n",
        "scaler = StandardScaler() # call an object function\n",
        "scaler.fit(X)   # calculate mean\n",
        "X = scaler.transform(X)  # apply normalization on X_train"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-TzI8R_1iIB",
        "colab_type": "text"
      },
      "source": [
        "#Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzKmOUGf1lDq",
        "colab_type": "text"
      },
      "source": [
        "Okay, so for the first function, all we'll do is find the distance to each center. Each row represents a data point and each column is for a cluster. For example, the $(10,1)$ entry is the distance from the 10th data point to the second center (since we start from 0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKWFFn9uioEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_dist_to_center(X, K, centers):\n",
        "    dist_to_center = np.zeros((X.shape[0],K), dtype = 'float')\n",
        "    for k in range(K):\n",
        "        for n in range(X.shape[0]):\n",
        "            #print(X[n,:])\n",
        "            dist_to_center[n][k] = np.linalg.norm(X[n,:] - centers[k, :])\n",
        "    #print(dist_to_center)\n",
        "    return dist_to_center     "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGERiVsg1_gf",
        "colab_type": "text"
      },
      "source": [
        "Once we've found our distances to the centers, we need to assign each data point to the cluster it is closest to. We'll do this by finding the argmin for row of the distance list we generate above and setting the corresponding entry in our \"cluster\" matrix as $1$ while the others are zeros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxHsjvyZgOiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def assign_center(dist_to_cluster, K):\n",
        "    cluster = np.zeros((X.shape[0], K), dtype = 'int')\n",
        "    for n in range(dist_to_cluster.shape[0]):\n",
        "        for k in range(K):\n",
        "            arg = np.argmin(dist_to_cluster[n, :])\n",
        "            if (k == arg):\n",
        "               cluster[n][k] = 1    \n",
        "    return cluster"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_6AyyRE2oED",
        "colab_type": "text"
      },
      "source": [
        "We'll now calculate the new centers based on our cluster groupings from before by taking the average of the entries of the data points of $X$ in each cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UISBcQn-L_32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_new_centers(X, K, in_which_cluster): \n",
        "    new_centers = np.zeros((K, X.shape[1]), dtype = 'float')\n",
        "    for k in range(K):\n",
        "        coordinates_sum = np.zeros(X.shape[1], dtype = 'float')\n",
        "        count = 0\n",
        "        for n in range(X.shape[0]):\n",
        "            if(in_which_cluster[n][k] != 0):\n",
        "                coordinates_sum = coordinates_sum + X[n,:]   \n",
        "                count = count + 1\n",
        "        #print(coordinates_sum)\n",
        "        if (count != 0):    \n",
        "            new_centers[k,:] = coordinates_sum/count\n",
        "    return new_centers"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vDkd5g72nFC",
        "colab_type": "text"
      },
      "source": [
        "Let's put this all together now and see what happens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7Yrscc-9-Sx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4b27302d-9ad0-450d-9c86-ae46947b7dce"
      },
      "source": [
        "K = 2 #number of clusters\n",
        "in_cluster = np.zeros((X.shape[0], K), dtype = 'int') #1 = in cluster, 0 otherwise\n",
        "center_coords =  np.random.rand(K,X.shape[1]) #save center coordinates\n",
        "for j in range(1000): #loop for Kmeans\n",
        "    dist = calc_dist_to_center(X, K, center_coords) \n",
        "    in_cluster = assign_center(dist, K)\n",
        "    center_coords = calc_new_centers(X, K, in_cluster)\n",
        "print(center_coords)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.50728948 -0.42663134  0.70710678]\n",
            " [-1.01457897  0.85326268 -1.41421356]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P89y7wn04dV",
        "colab_type": "text"
      },
      "source": [
        "Let's see how this compares to sklearn:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmY1q6b70crR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "73b980bf-9e12-4052-f1c7-225b383166c2"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters=2, random_state=42).fit(X)\n",
        "kmeans.cluster_centers_"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.01457897,  0.85326268, -1.41421356],\n",
              "       [ 0.50728948, -0.42663134,  0.70710678]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-ME0Atg1FuX",
        "colab_type": "text"
      },
      "source": [
        "It looks like my algorithm is relatively accurate, surprisingly enough. However, the sklearn algorithm is definitely much more efficient. I don't even want to discuss the difference in runtime."
      ]
    }
  ]
}